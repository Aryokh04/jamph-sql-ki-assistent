#!/usr/bin/env python3
"""Dockerise Model Script - Generate Dockerfile and deployment artifacts"""

import os
import sys
import json
import shutil
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# Load developer configuration from root
DEVELOPER_ENV_PATH = Path(__file__).parent.parent / "developer.env"
if DEVELOPER_ENV_PATH.exists():
    load_dotenv(DEVELOPER_ENV_PATH)

# ============================================================================
# CONFIGURATION
# ============================================================================

METADATA_CONFIG = {
    "dockerized_by": os.getenv("DEVELOPER_NAME", "Unknown Developer"),
    "organization": os.getenv("ORGANIZATION", "Unknown Organization"),
    "role": os.getenv("ROLE", "Unknown Role"),
}

SCRIPT_DIR = Path(__file__).parent
MODELS_DIR = SCRIPT_DIR / "model training" / "Models"
BACKEND_DIR = SCRIPT_DIR.parent / "backend"
BACKEND_MODELS_DIR = BACKEND_DIR / "models"

# ============================================================================
# UTILITIES
# ============================================================================

def print_header(text):
    print("\n" + "=" * 80)
    print(f"  {text}")
    print("=" * 80 + "\n")

def print_info(text):
    print(f"[INFO] {text}")

def print_success(text):
    print(f"[SUCCESS] {text}")

def print_error(text):
    print(f"[ERROR] {text}")

def print_warning(text):
    print(f"[WARNING] {text}")

# ============================================================================
# DOCKER ARTIFACT GENERATION
# ============================================================================

def generate_dockerfile(model_name, model_path):
    """Generate Dockerfile for Ollama model"""
    
    gguf_files = list(model_path.glob("*.gguf"))
    if not gguf_files:
        print_error(f"No GGUF file found in {model_path}")
        return None
    
    gguf_file = gguf_files[0].name
    
    dockerfile_content = f"""# Dockerfile for {model_name}
# Generated by dockerise_model.py on {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

FROM ollama/ollama:latest

# Set working directory
WORKDIR /app

# Copy model files
COPY {gguf_file} /app/
COPY Modelfile /app/

# Create model in Ollama
RUN ollama serve & \\
    sleep 5 && \\
    ollama create {model_name} -f /app/Modelfile && \\
    pkill ollama

# Expose Ollama port
EXPOSE 11434

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \\
    CMD curl -f http://localhost:11434/api/tags || exit 1

# Start Ollama server
CMD ["ollama", "serve"]
"""
    
    return dockerfile_content


def generate_docker_compose_entry(model_name):
    """Generate docker-compose service entry for model"""
    
    service_content = f"""
  {model_name}:
    build:
      context: ./backend/models/{model_name}
      dockerfile: Dockerfile
    container_name: {model_name}
    ports:
      - "11434:11434"
    volumes:
      - ollama-{model_name}:/root/.ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
"""
    
    return service_content


def generate_deployment_readme(model_name, model_path):
    """Generate deployment README for Docker setup"""
    
    quantization_config_path = model_path / "quantization_config.json"
    config = {}
    if quantization_config_path.exists():
        with open(quantization_config_path) as f:
            config = json.load(f)
    
    method = config.get("method", "Unknown")
    original_model = config.get("source_model", "Unknown")
    
    readme_content = f"""# {model_name} - Docker Deployment

## Overview
This directory contains the Docker deployment artifacts for the {model_name} model.

**Original Model:** {original_model}  
**Quantization:** {method}  
**Dockerized by:** {METADATA_CONFIG['dockerized_by']}  
**Organization:** {METADATA_CONFIG['organization']}  
**Date:** {datetime.now().strftime("%Y-%m-%d")}

## Quick Start

### Build and Run
```bash
# From project root
docker-compose up -d {model_name}
```

### Test the Model
```bash
# Check if container is running
docker ps | grep {model_name}

# Test API
curl http://localhost:11434/api/generate -d '{{
  "model": "{model_name}",
  "prompt": "Write a SQL query to select all users:",
  "stream": false
}}'
```

### Stop the Container
```bash
docker-compose down {model_name}
```

## Files
- `Dockerfile` - Container definition
- `{model_name}.gguf` - Quantized model (GGUF format)
- `Modelfile` - Ollama model configuration
- `LICENSE` - Model license
- `README.md` - This file

## API Usage

### Generate Text
```bash
curl http://localhost:11434/api/generate -d '{{
  "model": "{model_name}",
  "prompt": "Your prompt here",
  "stream": false
}}'
```

### Chat Completion
```bash
curl http://localhost:11434/api/chat -d '{{
  "model": "{model_name}",
  "messages": [
    {{"role": "user", "content": "Hello!"}}
  ]
}}'
```

## Configuration

### Environment Variables
- `OLLAMA_HOST`: Server address (default: 0.0.0.0:11434)
- `OLLAMA_MODELS`: Model storage path (default: /root/.ollama)
- `OLLAMA_NUM_PARALLEL`: Parallel requests (default: 1)

### Resource Requirements
- **RAM:** {config.get('ram_required', '8GB minimum')}
- **CPU:** {config.get('recommended_threads', '8+ threads recommended')}
- **Storage:** {config.get('file_size', 'Unknown')}

## Troubleshooting

### Container won't start
```bash
# Check logs
docker logs {model_name}

# Verify model creation
docker exec {model_name} ollama list
```

### Port already in use
Edit `docker-compose.yml` to use different port:
```yaml
ports:
  - "11435:11434"  # Changed from 11434
```

## Development

### Rebuild Container
```bash
docker-compose build {model_name}
docker-compose up -d {model_name}
```

### Access Container Shell
```bash
docker exec -it {model_name} /bin/bash
```

## Related Files
- Source quantization: `ai_models_training/Models/{model_name}/`
- Model documentation: See source directory for QUANTIZATION.md
"""
    
    return readme_content


def generate_dockerignore():
    """Generate .dockerignore for model directories"""
    
    dockerignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python

# Virtual environments
venv/
.venv/
env/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Documentation (already copied)
SOURCE_README.md
FINETUNING.md
QUANTIZATION.md

# Config files
quantization_config.json
"""
    
    return dockerignore_content


# ============================================================================
# MAIN WORKFLOW
# ============================================================================

def dockerise_model(model_name):
    """Generate Docker artifacts for a model"""
    
    print_header(f"Dockerising Model: {model_name}")
    
    # Locate source model
    source_model_path = MODELS_DIR / model_name
    if not source_model_path.exists():
        print_error(f"Model not found: {source_model_path}")
        return False
    
    print_info(f"Source: {source_model_path}")
    
    # Create backend model directory
    backend_model_path = BACKEND_MODELS_DIR / model_name
    backend_model_path.mkdir(parents=True, exist_ok=True)
    print_success(f"Created: {backend_model_path}")
    
    # Copy essential files
    essential_files = []
    
    # GGUF model (required)
    gguf_files = list(source_model_path.glob("*.gguf"))
    if not gguf_files:
        print_error("No GGUF file found")
        return False
    essential_files.append(gguf_files[0])
    
    # Modelfile (required)
    modelfile = source_model_path / "Modelfile"
    if not modelfile.exists():
        print_error("No Modelfile found")
        return False
    essential_files.append(modelfile)
    
    # LICENSE (optional)
    license_file = source_model_path / "LICENSE"
    if license_file.exists():
        essential_files.append(license_file)
    else:
        print_warning("No LICENSE file found")
    
    # QUANTIZATION.md (optional)
    quantization_md = source_model_path / "QUANTIZATION.md"
    if quantization_md.exists():
        essential_files.append(quantization_md)
    
    # FINETUNING.md (optional)
    finetuning_md = source_model_path / "FINETUNING.md"
    if finetuning_md.exists():
        essential_files.append(finetuning_md)
    
    # Copy files
    for file_path in essential_files:
        dest_path = backend_model_path / file_path.name
        shutil.copy2(file_path, dest_path)
        print_success(f"Copied: {file_path.name}")
    
    # Generate Dockerfile
    dockerfile_content = generate_dockerfile(model_name, source_model_path)
    if dockerfile_content:
        dockerfile_path = backend_model_path / "Dockerfile"
        with open(dockerfile_path, "w") as f:
            f.write(dockerfile_content)
        print_success("Created: Dockerfile")
    
    # Generate .dockerignore
    dockerignore_path = backend_model_path / ".dockerignore"
    with open(dockerignore_path, "w") as f:
        f.write(generate_dockerignore())
    print_success("Created: .dockerignore")
    
    # Generate deployment README
    deployment_readme = generate_deployment_readme(model_name, source_model_path)
    readme_path = backend_model_path / "README.md"
    with open(readme_path, "w") as f:
        f.write(deployment_readme)
    print_success("Created: README.md (deployment)")
    
    # Generate docker-compose entry
    compose_entry = generate_docker_compose_entry(model_name)
    compose_snippet_path = backend_model_path / "docker-compose.snippet.yml"
    with open(compose_snippet_path, "w") as f:
        f.write(compose_entry)
    print_success("Created: docker-compose.snippet.yml")
    
    print_header("Dockerisation Complete")
    print_info(f"Location: {backend_model_path}")
    print_info(f"\nNext steps:")
    print_info(f"1. Add docker-compose.snippet.yml content to root docker-compose.yml")
    print_info(f"2. Run: docker-compose build {model_name}")
    print_info(f"3. Run: docker-compose up -d {model_name}")
    
    return True


def main():
    """Main entry point"""
    
    print_header("Model Dockerisation Script")
    print_info(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if len(sys.argv) < 2:
        print_error("Usage: python dockerise_model.py <model_name>")
        print_info("\nAvailable models:")
        
        if MODELS_DIR.exists():
            for model_dir in sorted(MODELS_DIR.iterdir()):
                if model_dir.is_dir() and list(model_dir.glob("*.gguf")):
                    print_info(f"  - {model_dir.name}")
        else:
            print_error(f"Models directory not found: {MODELS_DIR}")
        
        sys.exit(1)
    
    model_name = sys.argv[1]
    
    try:
        success = dockerise_model(model_name)
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print_warning("\nInterrupted by user")
        sys.exit(130)
    except Exception as e:
        print_error(f"Failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
